# A total of 16 32GB GPUs were used for training.

trainer: forces

dataset:
  - src: /mnt/datasets/s2ef/2M/train/
    normalize_labels: True
    target_mean: -0.7554450631141663
    target_std: 2.887317180633545
    grad_target_mean: 0.0
    grad_target_std: 2.887317180633545
  - src: /mnt/datasets/s2ef/all/val_id/


logger: wandb

task:
    dataset: trajectory_lmdb
    description: "Regressing to energies and forces for DFT trajectories from OCP"
    type: regression
    metric: mae
    labels:
        - potential energy
    grad_input: atomic forces
    train_on_free_atoms: True
    eval_on_free_atoms: True

model:
    name: rhescn
    num_layers: 12
    max_neighbors: 20
    cutoff: 12.0
    sphere_channels: 128
    hidden_channels: 256
    lmax_list: [8]
    mmax_list: [4]
    num_sphere_samples: 128
    distance_function: "gaussian"
    regress_forces: True
    use_pbc: True
    basis_width_scalar: 2.0
    otf_graph: True
    show_timing_info: False

    wigner_fp16: False
    grid_fp16: False

    stacked_m0: True
    skip_first_layer: True

optim:
    # batch_size: 2
    # eval_batch_size: 6
    batch_size: 1
    eval_batch_size: 1
    num_workers: 8
    lr_initial: 0.0004
    optimizer: AdamW
    optimizer_params: {"amsgrad": True}
    eval_every: 5000
    lr_gamma: 0.3
    lr_milestones: # epochs at which lr_initial <- lr_initial * lr_gamma
        - 145833
        - 187500
        - 229166
    warmup_steps: 100
    warmup_factor: 0.2
    max_epochs: 12
    force_coefficient: 100
    energy_coefficient: 2
    clip_grad_norm: 20
    ema_decay: 0.999
    loss_energy: mae
    loss_force: l2mae
